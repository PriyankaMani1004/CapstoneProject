{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40189c2b-874b-4cdb-92d6-0dc24729148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from RFE_FeatureSelection import FeatureSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca2babfa-3425-43b8-b871-7dd327080c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_Size</th>\n",
       "      <th>Project_Budget_USD</th>\n",
       "      <th>Estimated_Timeline_Months</th>\n",
       "      <th>Complexity_Score</th>\n",
       "      <th>Stakeholder_Count</th>\n",
       "      <th>Past_Similar_Projects</th>\n",
       "      <th>External_Dependencies_Count</th>\n",
       "      <th>Change_Request_Frequency</th>\n",
       "      <th>Team_Turnover_Rate</th>\n",
       "      <th>Vendor_Reliability_Score</th>\n",
       "      <th>...</th>\n",
       "      <th>Tech_Environment_Stability</th>\n",
       "      <th>Contract_Type</th>\n",
       "      <th>Resource_Contention_Level</th>\n",
       "      <th>Industry_Volatility</th>\n",
       "      <th>Client_Experience_Level</th>\n",
       "      <th>Change_Control_Maturity</th>\n",
       "      <th>Risk_Management_Maturity</th>\n",
       "      <th>Team_Colocation</th>\n",
       "      <th>Documentation_Quality</th>\n",
       "      <th>Risk_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>1526276.550</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.70</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>390790.150</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.72</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.79</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>246674.760</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.89</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1427830.630</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.54</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.42</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.84</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1696746.640</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.68</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.86</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>9.0</td>\n",
       "      <td>731548.970</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.40</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>9.0</td>\n",
       "      <td>492981.400</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.69</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1097040.650</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.82</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>26.0</td>\n",
       "      <td>2650876.115</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>33.0</td>\n",
       "      <td>1627904.310</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.04</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.78</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team_Size  Project_Budget_USD  Estimated_Timeline_Months  \\\n",
       "0          32.0         1526276.550                       32.0   \n",
       "1           2.0          390790.150                        9.0   \n",
       "2           2.0          246674.760                        6.0   \n",
       "3          12.0         1427830.630                       17.0   \n",
       "4          24.0         1696746.640                       24.0   \n",
       "...         ...                 ...                        ...   \n",
       "3995        9.0          731548.970                       14.0   \n",
       "3996        9.0          492981.400                        9.0   \n",
       "3997       12.0         1097040.650                       24.0   \n",
       "3998       26.0         2650876.115                       28.0   \n",
       "3999       33.0         1627904.310                       28.0   \n",
       "\n",
       "      Complexity_Score  Stakeholder_Count  Past_Similar_Projects  \\\n",
       "0                 9.70               16.0                    3.0   \n",
       "1                 2.72                9.0                    0.0   \n",
       "2                 2.04                7.0                    1.0   \n",
       "3                 7.54               16.0                    0.0   \n",
       "4                 6.68               17.0                    0.0   \n",
       "...                ...                ...                    ...   \n",
       "3995              5.40                9.0                    4.0   \n",
       "3996              2.69                8.0                    5.0   \n",
       "3997              8.82               10.0                    2.0   \n",
       "3998             10.00               23.0                    1.0   \n",
       "3999              7.04               15.0                    1.0   \n",
       "\n",
       "      External_Dependencies_Count  Change_Request_Frequency  \\\n",
       "0                             3.0                      1.05   \n",
       "1                             2.0                      2.61   \n",
       "2                             0.0                      0.83   \n",
       "3                             5.0                      2.42   \n",
       "4                             2.0                      0.16   \n",
       "...                           ...                       ...   \n",
       "3995                          3.0                      1.09   \n",
       "3996                          3.0                      2.11   \n",
       "3997                          4.0                      0.52   \n",
       "3998                          6.0                      1.19   \n",
       "3999                          3.0                      1.56   \n",
       "\n",
       "      Team_Turnover_Rate  Vendor_Reliability_Score  ...  \\\n",
       "0                   0.16                      0.84  ...   \n",
       "1                   0.42                      0.79  ...   \n",
       "2                   0.55                      0.89  ...   \n",
       "3                   0.33                      0.84  ...   \n",
       "4                   0.36                      0.86  ...   \n",
       "...                  ...                       ...  ...   \n",
       "3995                0.25                      0.94  ...   \n",
       "3996                0.06                      0.71  ...   \n",
       "3997                0.23                      0.95  ...   \n",
       "3998                0.30                      0.50  ...   \n",
       "3999                0.25                      0.78  ...   \n",
       "\n",
       "      Tech_Environment_Stability  Contract_Type  Resource_Contention_Level  \\\n",
       "0                              0              3                          0   \n",
       "1                              0              0                          1   \n",
       "2                              0              0                          0   \n",
       "3                              2              2                          0   \n",
       "4                              0              0                          0   \n",
       "...                          ...            ...                        ...   \n",
       "3995                           1              1                          2   \n",
       "3996                           0              1                          2   \n",
       "3997                           1              3                          1   \n",
       "3998                           0              1                          2   \n",
       "3999                           0              2                          0   \n",
       "\n",
       "      Industry_Volatility  Client_Experience_Level  Change_Control_Maturity  \\\n",
       "0                       0                        0                        2   \n",
       "1                       3                        1                        1   \n",
       "2                       3                        2                        0   \n",
       "3                       0                        3                        3   \n",
       "4                       2                        1                        2   \n",
       "...                   ...                      ...                      ...   \n",
       "3995                    2                        1                        0   \n",
       "3996                    3                        1                        0   \n",
       "3997                    2                        2                        0   \n",
       "3998                    1                        3                        2   \n",
       "3999                    1                        1                        3   \n",
       "\n",
       "      Risk_Management_Maturity  Team_Colocation  Documentation_Quality  \\\n",
       "0                            2                0                      2   \n",
       "1                            3                1                      3   \n",
       "2                            0                2                      2   \n",
       "3                            2                2                      0   \n",
       "4                            0                3                      0   \n",
       "...                        ...              ...                    ...   \n",
       "3995                         0                2                      0   \n",
       "3996                         2                2                      0   \n",
       "3997                         2                1                      0   \n",
       "3998                         3                1                      2   \n",
       "3999                         3                3                      0   \n",
       "\n",
       "      Risk_Level  \n",
       "0           High  \n",
       "1            Low  \n",
       "2         Medium  \n",
       "3           High  \n",
       "4           High  \n",
       "...          ...  \n",
       "3995        High  \n",
       "3996      Medium  \n",
       "3997        High  \n",
       "3998        High  \n",
       "3999      Medium  \n",
       "\n",
       "[4000 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the Dataset\n",
    "dataset = pd.read_csv(r\"D:\\AI course Tamil\\CapstoneProject\\2.Data Preprocessing\\Preprocessed_project_risk.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e617b3e2-62bb-4728-ba2b-22900ae93bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 50)\n",
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "# Separate target first\n",
    "dependent = dataset[\"Risk_Level\"]\n",
    "independent = dataset.drop(columns=[\"Risk_Level\"])\n",
    "\n",
    "# Apply get_dummies only on independent\n",
    "X_encoded = pd.get_dummies(independent, drop_first=True)\n",
    "X_encoded=X_encoded.replace({True:1,False:0})\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "Y_encoded = le.fit_transform(dependent)\n",
    "print(X_encoded.shape)\n",
    "print(Y_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b0456bc-4438-43ff-802b-667689546aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "var_selector = VarianceThreshold(threshold=0.01)\n",
    "X_var = var_selector.fit_transform(X_encoded)\n",
    "\n",
    "X_var_columns = X_encoded.columns[var_selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9928743-ae4f-4a71-b657-164bbca01589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Team_Size', 'Project_Budget_USD', 'Estimated_Timeline_Months',\n",
       "       'Complexity_Score', 'Stakeholder_Count', 'Past_Similar_Projects',\n",
       "       'External_Dependencies_Count', 'Change_Request_Frequency',\n",
       "       'Team_Turnover_Rate', 'Vendor_Reliability_Score',\n",
       "       'Historical_Risk_Incidents', 'Communication_Frequency',\n",
       "       'Geographical_Distribution', 'Budget_Utilization_Rate',\n",
       "       'Market_Volatility', 'Integration_Complexity', 'Resource_Availability',\n",
       "       'Organizational_Change_Frequency', 'Cross_Functional_Dependencies',\n",
       "       'Previous_Delivery_Success_Rate', 'Technical_Debt_Level',\n",
       "       'Project_Start_Month', 'Current_Phase_Duration_Months', 'Project_ID',\n",
       "       'Project_Type', 'Methodology_Used', 'Team_Experience_Level',\n",
       "       'Project_Phase', 'Requirement_Stability', 'Regulatory_Compliance_Level',\n",
       "       'Technology_Familiarity', 'Stakeholder_Engagement_Level',\n",
       "       'Executive_Sponsorship', 'Funding_Source', 'Priority_Level',\n",
       "       'Project_Manager_Experience', 'Org_Process_Maturity',\n",
       "       'Data_Security_Requirements', 'Key_Stakeholder_Availability',\n",
       "       'Tech_Environment_Stability', 'Contract_Type',\n",
       "       'Resource_Contention_Level', 'Industry_Volatility',\n",
       "       'Client_Experience_Level', 'Change_Control_Maturity',\n",
       "       'Risk_Management_Maturity', 'Team_Colocation', 'Documentation_Quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_var_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "824eecf1-565c-402c-a8ec-9f51ecdcfb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              feature_weights=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
      "              n_jobs=None, num_parallel_tree=None, ...)\n",
      "RandomForestClassifier(criterion='entropy', random_state=0)\n",
      "DecisionTreeClassifier(random_state=0)\n",
      "LGBMClassifier(n_estimators=200, random_state=0)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2591\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Anaconda3\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Anaconda3\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Anaconda3\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2591\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2587\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2581\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2577\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2572\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2568\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2562\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 43\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2557\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 42\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2527\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2519\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2498\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2485\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2481\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2477\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2473\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2402\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2398\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 31\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2384\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2381\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2377\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2373\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2369\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2365\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2357\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2353\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2350\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2315\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2310\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2305\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2301\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2246\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2181\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2109\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.658103\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "[LightGBM] [Info] Start training from score -1.052683\n"
     ]
    }
   ],
   "source": [
    "rfelist=FeatureSelection.rfeFeature(X_encoded,Y_encoded,10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e804b9f-5d1f-40b3-894f-2931677efb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.7368693998892468\n",
      "ROC AUC: 0.557967317109444\n",
      "ROC AUC: 0.6737839480413113\n",
      "ROC AUC: 0.7097953294408653\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 476\n",
      "[LightGBM] [Info] Number of data points in the train set: 3000, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.669542\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.579879\n",
      "[LightGBM] [Info] Start training from score -1.059392\n",
      "ROC AUC: 0.7031746009922506\n",
      "ROC AUC: 0.7555187713136536\n",
      "ROC AUC: 0.6199156167779577\n",
      "ROC AUC: 0.7450390288908978\n",
      "ROC AUC: 0.7942353286119332\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 3000, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.669542\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.579879\n",
      "[LightGBM] [Info] Start training from score -1.059392\n",
      "ROC AUC: 0.7824614341278688\n",
      "ROC AUC: 0.664311981896614\n",
      "ROC AUC: 0.5304256596297618\n",
      "ROC AUC: 0.601944093660719\n",
      "ROC AUC: 0.6307754808203563\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 3000, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.669542\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.579879\n",
      "[LightGBM] [Info] Start training from score -1.059392\n",
      "ROC AUC: 0.6275924938547187\n",
      "ROC AUC: 0.6611645373568182\n",
      "ROC AUC: 0.545169826347433\n",
      "ROC AUC: 0.6103185714508779\n",
      "ROC AUC: 0.6339047147732091\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1843\n",
      "[LightGBM] [Info] Number of data points in the train set: 3000, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.669542\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.579879\n",
      "[LightGBM] [Info] Start training from score -1.059392\n",
      "ROC AUC: 0.6289666075987206\n",
      "ROC AUC: 0.6572106258534259\n",
      "ROC AUC: 0.5302493228291368\n",
      "ROC AUC: 0.6083332449303873\n",
      "ROC AUC: 0.6276000574076765\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2034\n",
      "[LightGBM] [Info] Number of data points in the train set: 3000, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.669542\n",
      "[LightGBM] [Info] Start training from score -1.350927\n",
      "[LightGBM] [Info] Start training from score -1.579879\n",
      "[LightGBM] [Info] Start training from score -1.059392\n",
      "ROC AUC: 0.6207152063657635\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "      <th>XGB</th>\n",
       "      <th>LGB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.499</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC_AUC</th>\n",
       "      <td>0.755519</td>\n",
       "      <td>0.619916</td>\n",
       "      <td>0.745039</td>\n",
       "      <td>0.794235</td>\n",
       "      <td>0.782461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Logistic  Decision    Random       XGB       LGB\n",
       "Accuracy     0.499     0.429     0.495      0.53      0.52\n",
       "ROC_AUC   0.755519  0.619916  0.745039  0.794235  0.782461"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acclog=[]\n",
    "accdes=[]\n",
    "accrf=[]\n",
    "accxgb=[]\n",
    "acclgb=[]\n",
    "\n",
    "\n",
    "for i in rfelist:   \n",
    "    X_train, X_test, y_train, y_test=FeatureSelection.split_scalar(i,Y_encoded)   \n",
    "    \n",
    "        \n",
    "    classifier,Accuracy,report,X_test,y_test,cm,roc_auc=FeatureSelection.logistic(X_train,y_train,X_test,y_test)\n",
    "    acclog.append((Accuracy, roc_auc))\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm,roc_auc=FeatureSelection.Decision(X_train,y_train,X_test,y_test)  \n",
    "    accdes.append((Accuracy, roc_auc))\n",
    "\n",
    "    classifier,Accuracy,report,X_test,y_test,cm,roc_auc=FeatureSelection.random(X_train,y_train,X_test,y_test)  \n",
    "    accrf.append((Accuracy, roc_auc))\n",
    "   \n",
    "    classifier,Accuracy,report,X_test,y_test,cm,roc_auc=FeatureSelection.Xgb(X_train,y_train,X_test,y_test)  \n",
    "    accxgb.append((Accuracy, roc_auc))\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm,roc_auc=FeatureSelection.Lgb(X_train,y_train,X_test,y_test)  \n",
    "    acclgb.append((Accuracy, roc_auc))\n",
    "   \n",
    "result=FeatureSelection.rfe_classification(acclog,accdes,accrf,accxgb,acclgb)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f878a51-21ef-4fcf-bd31-fc3ed6deecfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
